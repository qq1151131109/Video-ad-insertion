"""
äººè„¸æ£€æµ‹æµ‹è¯•è„šæœ¬

æµ‹è¯•MTCNNäººè„¸æ£€æµ‹åŠŸèƒ½
"""
import sys
from pathlib import Path
import cv2

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.face_detector import FaceDetector
from src.core.video_processor import VideoProcessor
from src.utils.file_manager import TempFileManager
from src.utils.logger import logger
from src.config.settings import settings


def test_face_detector_installation():
    """æµ‹è¯•äººè„¸æ£€æµ‹å™¨æ˜¯å¦å·²å®‰è£…"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•1: æ£€æŸ¥MTCNNå®‰è£…")
    logger.info("=" * 60)

    if FaceDetector.check_installation():
        logger.success("âœ“ MTCNNå·²å®‰è£…")
        return True
    else:
        logger.error("âœ— MTCNNæœªå®‰è£…")
        logger.info("\nå®‰è£…æ–¹æ³•:")
        logger.info("  pip install mtcnn tensorflow")
        return False


def test_face_detection():
    """æµ‹è¯•äººè„¸æ£€æµ‹"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•2: äººè„¸æ£€æµ‹")
    logger.info("=" * 60)

    # æŸ¥æ‰¾æµ‹è¯•è§†é¢‘
    video_files = list(settings.INPUT_DIR.glob("*.mp4"))
    if not video_files:
        logger.error("âŒ inputç›®å½•ä¸‹æ²¡æœ‰è§†é¢‘æ–‡ä»¶")
        return False

    video_path = video_files[0]
    video_id = video_path.stem

    logger.info(f"æµ‹è¯•è§†é¢‘: {video_path.name}")

    try:
        with TempFileManager(video_id) as file_mgr:
            # 1. æå–å…³é”®å¸§
            logger.info("\næ­¥éª¤1: æå–å…³é”®å¸§")
            with VideoProcessor(str(video_path)) as processor:
                metadata = processor.extract_metadata()
                logger.info(f"è§†é¢‘æ—¶é•¿: {metadata.duration:.1f}ç§’")

                # æå–ä¸­é—´ä½ç½®çš„å…³é”®å¸§
                mid_time = metadata.duration / 2
                frame, actual_time = processor.extract_best_frame_around_time(
                    target_time=mid_time,
                    window_size=2.0,
                    num_candidates=10
                )

            logger.info(f"å…³é”®å¸§æ—¶é—´: {actual_time:.2f}ç§’")
            logger.info(f"å¸§å°ºå¯¸: {frame.shape[1]}x{frame.shape[0]}")

            # 2. äººè„¸æ£€æµ‹
            logger.info("\næ­¥éª¤2: æ£€æµ‹äººè„¸")
            logger.info("âš ï¸  é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½MTCNNæ¨¡å‹")

            detector = FaceDetector(
                min_face_size=20,
                confidence_threshold=0.9
            )

            faces = detector.detect_faces(frame)

            # 3. æ˜¾ç¤ºç»“æœ
            logger.info("\n" + "=" * 60)
            logger.info("æ£€æµ‹ç»“æœ")
            logger.info("=" * 60)
            logger.info(f"æ£€æµ‹åˆ° {len(faces)} ä¸ªäººè„¸")

            if faces:
                for i, face in enumerate(faces, 1):
                    logger.info(f"\näººè„¸ {i}:")
                    logger.info(f"  ç½®ä¿¡åº¦: {face.confidence:.3f}")
                    logger.info(f"  ä½ç½®: {[int(v) for v in face.bbox]}")
                    logger.info(f"  å°ºå¯¸: {face.width:.0f}x{face.height:.0f}")
                    logger.info(f"  é¢ç§¯: {face.area:.0f}åƒç´ Â²")
                    logger.info(f"  ä¸­å¿ƒ: ({face.center[0]:.0f}, {face.center[1]:.0f})")

                # æµ‹è¯•æ¸…æ™°äººè„¸æ£€æŸ¥
                has_clear = detector.has_clear_face(frame, min_face_ratio=0.05)
                logger.info(f"\næ˜¯å¦æœ‰æ¸…æ™°äººè„¸: {'æ˜¯' if has_clear else 'å¦'}")

                # æµ‹è¯•æœ€ä½³äººè„¸è·å–
                best_face = detector.get_best_face(frame)
                if best_face:
                    logger.info(f"æœ€ä½³äººè„¸ç½®ä¿¡åº¦: {best_face.confidence:.3f}")

                # æµ‹è¯•è´¨é‡è¯„åˆ†
                sharpness = cv2.Laplacian(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()
                quality_score = detector.score_frame_quality(
                    frame,
                    sharpness_score=sharpness,
                    face_weight=0.3,
                    sharpness_weight=0.7
                )
                logger.info(f"\nå¸§è´¨é‡è¯„åˆ†:")
                logger.info(f"  æ¸…æ™°åº¦: {sharpness:.1f}")
                logger.info(f"  ç»¼åˆè¯„åˆ†: {quality_score:.3f}")

                # ä¿å­˜å¸¦æ ‡æ³¨çš„å›¾åƒ
                output_path = file_mgr.get_path("keyframes", "face_detection_result.jpg")
                annotated = FaceDetector.draw_faces(frame, faces)
                cv2.imwrite(str(output_path), annotated)
                logger.info(f"\næ ‡æ³¨å›¾åƒå·²ä¿å­˜: {output_path}")

                logger.success("\nâœ“ äººè„¸æ£€æµ‹æˆåŠŸ")
                return True
            else:
                logger.warning("\nâš ï¸  æœªæ£€æµ‹åˆ°äººè„¸")
                logger.info("å¯èƒ½åŸå› :")
                logger.info("  1. è§†é¢‘ä¸­æ²¡æœ‰äººè„¸")
                logger.info("  2. ç½®ä¿¡åº¦é˜ˆå€¼è¿‡é«˜")
                logger.info("  3. äººè„¸å¤ªå°æˆ–æ¨¡ç³Š")
                return True  # ä¸ç®—å¤±è´¥ï¼Œåªæ˜¯æ²¡æ£€æµ‹åˆ°

    except ImportError as e:
        if "mtcnn" in str(e).lower() or "tensorflow" in str(e).lower():
            logger.error("âœ— MTCNNæˆ–TensorFlowæœªå®‰è£…")
            logger.info("\nå®‰è£…æ–¹æ³•:")
            logger.info("  pip install mtcnn tensorflow")
        else:
            logger.error(f"âœ— å¯¼å…¥é”™è¯¯: {e}")
        return False

    except Exception as e:
        logger.error(f"âœ— äººè„¸æ£€æµ‹å¤±è´¥: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return False


def test_multiple_frames():
    """æµ‹è¯•å¤šå¸§äººè„¸æ£€æµ‹ï¼ˆé€‰æ‹©æœ€ä½³äººè„¸å¸§ï¼‰"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•3: å¤šå¸§æœ€ä½³äººè„¸é€‰æ‹©")
    logger.info("=" * 60)

    # æŸ¥æ‰¾æµ‹è¯•è§†é¢‘
    video_files = list(settings.INPUT_DIR.glob("*.mp4"))
    if not video_files:
        logger.error("âŒ inputç›®å½•ä¸‹æ²¡æœ‰è§†é¢‘æ–‡ä»¶")
        return False

    video_path = video_files[0]
    video_id = video_path.stem

    logger.info(f"æµ‹è¯•è§†é¢‘: {video_path.name}")

    try:
        with TempFileManager(video_id) as file_mgr:
            with VideoProcessor(str(video_path)) as processor:
                metadata = processor.extract_metadata()

                # æå–å¤šä¸ªæ—¶é—´ç‚¹çš„å¸§
                times = [
                    metadata.duration * 0.25,
                    metadata.duration * 0.5,
                    metadata.duration * 0.75
                ]

                logger.info(f"æµ‹è¯•æ—¶é—´ç‚¹: {[f'{t:.1f}s' for t in times]}")

                detector = FaceDetector()
                results = []

                for i, time in enumerate(times, 1):
                    logger.info(f"\næ£€æµ‹å¸§ {i} ({time:.1f}s)...")

                    frame, actual_time = processor.extract_best_frame_around_time(
                        target_time=time,
                        window_size=1.0
                    )

                    faces = detector.detect_faces(frame)
                    best_face = detector.get_best_face(frame)

                    sharpness = cv2.Laplacian(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()
                    quality = detector.score_frame_quality(frame, sharpness)

                    results.append({
                        'time': actual_time,
                        'faces': len(faces),
                        'best_face': best_face,
                        'quality': quality,
                        'frame': frame
                    })

                    logger.info(f"  äººè„¸æ•°: {len(faces)}")
                    if best_face:
                        logger.info(f"  æœ€ä½³äººè„¸ç½®ä¿¡åº¦: {best_face.confidence:.3f}")
                    logger.info(f"  è´¨é‡è¯„åˆ†: {quality:.3f}")

                # é€‰æ‹©æœ€ä½³å¸§
                best_result = max(results, key=lambda r: r['quality'])

                logger.info("\n" + "=" * 60)
                logger.info("æœ€ä½³å…³é”®å¸§")
                logger.info("=" * 60)
                logger.info(f"æ—¶é—´: {best_result['time']:.1f}ç§’")
                logger.info(f"äººè„¸æ•°: {best_result['faces']}")
                logger.info(f"è´¨é‡è¯„åˆ†: {best_result['quality']:.3f}")

                # ä¿å­˜æœ€ä½³å¸§
                output_path = file_mgr.get_path("keyframes", "best_face_frame.jpg")
                cv2.imwrite(str(output_path), best_result['frame'])
                logger.info(f"\næœ€ä½³å¸§å·²ä¿å­˜: {output_path}")

                logger.success("\nâœ“ å¤šå¸§æ£€æµ‹æˆåŠŸ")
                return True

    except Exception as e:
        logger.error(f"âœ— å¤šå¸§æ£€æµ‹å¤±è´¥: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹äººè„¸æ£€æµ‹æ¨¡å—æµ‹è¯•\n")

    # æµ‹è¯•1: æ£€æŸ¥å®‰è£…
    installation_ok = test_face_detector_installation()

    if not installation_ok:
        logger.error("\nâŒ MTCNNæœªå®‰è£…ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        logger.info("\nè¯·å…ˆå®‰è£…ä¾èµ–:")
        logger.info("  pip install mtcnn tensorflow")
        return 1

    # æµ‹è¯•2: äººè„¸æ£€æµ‹
    detection_ok = test_face_detection()

    # æµ‹è¯•3: å¤šå¸§æ£€æµ‹
    multi_frame_ok = test_multiple_frames()

    # æ±‡æ€»
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•æ±‡æ€»")
    logger.info("=" * 60)
    logger.info(f"1. MTCNNå®‰è£…: {'âœ“ é€šè¿‡' if installation_ok else 'âœ— å¤±è´¥'}")
    logger.info(f"2. äººè„¸æ£€æµ‹: {'âœ“ é€šè¿‡' if detection_ok else 'âœ— å¤±è´¥'}")
    logger.info(f"3. å¤šå¸§æ£€æµ‹: {'âœ“ é€šè¿‡' if multi_frame_ok else 'âœ— å¤±è´¥'}")

    if installation_ok and detection_ok and multi_frame_ok:
        logger.success("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        logger.error("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    sys.exit(main())
