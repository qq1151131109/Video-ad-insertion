"""
å®Œæ•´è§†é¢‘å¤„ç†æµæ°´çº¿

æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œå®ç°ä»è¾“å…¥è§†é¢‘åˆ°è¾“å‡ºå¸¦å¹¿å‘Šè§†é¢‘çš„å®Œæ•´å¤„ç†æµç¨‹
"""
from pathlib import Path
from typing import Optional
from dataclasses import dataclass
import time

from src.core.video_processor import VideoProcessor
from src.core.audio_separator import AudioSeparator
from src.core.asr import ASRService
from src.core.face_detector import FaceDetector
from src.core.speaker_detector import SpeakerDetector, VideoSceneType, SpeakerProfile
from src.services.llm_service import LLMService, InsertionPoint
from src.config.ads import AdsManager
from src.core.ad_orchestrator import AdVideoOrchestrator
from src.core.video_composer import VideoComposer
from src.utils.file_manager import TempFileManager
from src.utils.logger import logger
from src.config.settings import settings
import numpy as np
import cv2


@dataclass
class ProcessingResult:
    """å¤„ç†ç»“æœ"""
    video_id: str
    original_video_path: str
    output_video_path: Optional[str]
    success: bool
    error_message: Optional[str] = None
    processing_time: float = 0.0  # å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰

    # ä¸­é—´ç»“æœ
    transcription_text: Optional[str] = None
    video_theme: Optional[str] = None
    insertion_time: Optional[float] = None
    ad_script: Optional[str] = None
    digital_human_video: Optional[str] = None


class VideoPipeline:
    """è§†é¢‘å¤„ç†æµæ°´çº¿"""

    def __init__(self):
        """åˆå§‹åŒ–æµæ°´çº¿"""
        logger.info("åˆå§‹åŒ–è§†é¢‘å¤„ç†æµæ°´çº¿...")

        # åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡
        self.audio_separator = AudioSeparator(model="htdemucs")
        self.asr_service = ASRService(model_name="medium")  # ä½¿ç”¨mediumæ¨¡å‹å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
        self.face_detector = FaceDetector()
        self.speaker_detector = SpeakerDetector(self.face_detector)  # ä¸»è®²äººæ£€æµ‹å™¨
        self.llm_service = LLMService()
        self.ads_manager = AdsManager()
        self.ad_orchestrator = AdVideoOrchestrator()
        self.video_composer = VideoComposer()

        logger.success("âœ“ æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")

    def process_video(
        self,
        video_path: str,
        output_dir: Optional[str] = None,
        device: str = "cuda"
    ) -> ProcessingResult:
        """
        å¤„ç†è§†é¢‘ï¼ˆå®Œæ•´æµç¨‹ï¼‰

        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼ˆNoneåˆ™ä½¿ç”¨é»˜è®¤ï¼‰
            device: è®¾å¤‡ï¼ˆcuda/cpuï¼‰

        Returns:
            å¤„ç†ç»“æœ
        """
        start_time = time.time()

        video_path = Path(video_path)
        video_id = video_path.stem

        if not video_path.exists():
            return ProcessingResult(
                video_id=video_id,
                original_video_path=str(video_path),
                output_video_path=None,
                success=False,
                error_message=f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"
            )

        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = settings.OUTPUT_DIR / "processed" / video_id
        else:
            output_dir = Path(output_dir)

        output_dir.mkdir(parents=True, exist_ok=True)

        logger.info("=" * 80)
        logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path.name}")
        logger.info("=" * 80)

        try:
            with TempFileManager(video_id) as file_mgr:
                # ============================================================
                # é˜¶æ®µ1: è§†é¢‘åˆ†æ
                # ============================================================
                logger.info("\n" + "=" * 80)
                logger.info("é˜¶æ®µ1: è§†é¢‘åˆ†æ")
                logger.info("=" * 80)

                # 1.1 æå–å…ƒæ•°æ®
                logger.info("\n[1/3] æå–è§†é¢‘å…ƒæ•°æ®...")
                with VideoProcessor(str(video_path)) as processor:
                    metadata = processor.extract_metadata()

                logger.info(f"  æ—¶é•¿: {metadata.duration:.1f}ç§’")
                logger.info(f"  åˆ†è¾¨ç‡: {metadata.resolution}")
                logger.info(f"  å¸§ç‡: {metadata.fps}")

                # æ£€æŸ¥è§†é¢‘æ—¶é•¿
                if metadata.duration < settings.MIN_VIDEO_DURATION:
                    raise Exception(f"è§†é¢‘å¤ªçŸ­({metadata.duration:.1f}s)ï¼Œæœ€å°è¦æ±‚{settings.MIN_VIDEO_DURATION}s")

                if metadata.duration > settings.MAX_VIDEO_DURATION:
                    raise Exception(f"è§†é¢‘å¤ªé•¿({metadata.duration:.1f}s)ï¼Œæœ€å¤§é™åˆ¶{settings.MAX_VIDEO_DURATION}s")

                # 1.2 æå–éŸ³é¢‘
                logger.info("\n[2/3] æå–éŸ³é¢‘...")
                with VideoProcessor(str(video_path)) as processor:
                    audio_path = processor.extract_audio(
                        str(file_mgr.original_audio_path)
                    )

                logger.success(f"  âœ“ éŸ³é¢‘å·²æå–: {Path(audio_path).name}")

                # 1.3 äººå£°åˆ†ç¦»
                logger.info("\n[3/3] åˆ†ç¦»äººå£°...")
                vocals_path = self.audio_separator.separate_simple(
                    audio_path=audio_path,
                    output_path=str(file_mgr.separated_vocals_path),
                    device=device
                )

                logger.success(f"  âœ“ äººå£°å·²åˆ†ç¦»: {Path(vocals_path).name}")

                # ============================================================
                # é˜¶æ®µ2: å†…å®¹ç†è§£
                # ============================================================
                logger.info("\n" + "=" * 80)
                logger.info("é˜¶æ®µ2: å†…å®¹ç†è§£")
                logger.info("=" * 80)

                # 2.1 è¯­éŸ³è¯†åˆ«
                logger.info("\n[1/2] è¯­éŸ³è¯†åˆ«...")
                transcription = self.asr_service.transcribe(
                    audio_path=audio_path,
                    language=None,  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
                    word_timestamps=True
                )

                logger.success(f"  âœ“ è¯†åˆ«å®Œæˆ: {len(transcription.segments)}ä¸ªç‰‡æ®µ")
                logger.info(f"  æ£€æµ‹è¯­è¨€: {transcription.language}")
                logger.info(f"  æ–‡æœ¬é¢„è§ˆ: {transcription.full_text[:100]}...")

                # ä¿å­˜è½¬å½•ç»“æœ
                transcription_path = file_mgr.get_transcription_path()
                file_mgr.save_text("transcriptions", "transcription.txt", transcription.full_text)

                # ä¿å­˜SRTå­—å¹•
                srt_content = transcription.to_srt()
                file_mgr.save_text("transcriptions", "subtitles.srt", srt_content)

                # 2.2 LLMå†…å®¹åˆ†æ
                logger.info("\n[2/2] LLMå†…å®¹åˆ†æ...")

                # è½¬æ¢ä¸ºLLMæ‰€éœ€æ ¼å¼
                segments = [
                    {"text": seg.text, "start": seg.start, "end": seg.end}
                    for seg in transcription.segments
                ]

                analysis = self.llm_service.analyze_video_content(
                    transcription_segments=segments,
                    video_duration=metadata.duration,
                    avoid_start=settings.INSERTION_POINT_AVOID_START,
                    avoid_end=settings.INSERTION_POINT_AVOID_END,
                    num_candidates=3
                )

                logger.success("  âœ“ å†…å®¹åˆ†æå®Œæˆ")
                logger.info(f"  ä¸»é¢˜: {analysis.theme}")
                logger.info(f"  ç±»åˆ«: {analysis.category}")
                logger.info(f"  æ‰¾åˆ°{len(analysis.insertion_points)}ä¸ªæ’å…¥ç‚¹å€™é€‰")

                # ============================================================
                # é˜¶æ®µ2.5: åœºæ™¯åˆ†æï¼ˆæ–°å¢ï¼‰
                # ============================================================
                logger.info("\n" + "=" * 80)
                logger.info("é˜¶æ®µ2.5: åœºæ™¯åˆ†æ")
                logger.info("=" * 80)

                scene = self.speaker_detector.analyze_video_scene(
                    video_path,
                    metadata.duration
                )

                if not scene.is_single_speaker:
                    logger.warning(
                        f"âš ï¸ è§†é¢‘ä¸æ˜¯å•äººå£æ’­åœºæ™¯\n"
                        f"  æœ‰äººè„¸çš„å¸§: {scene.frames_with_faces}/{scene.total_sampled_frames}\n"
                        f"  æ£€æµ‹åˆ°è®²è€…æ•°: {scene.unique_speakers}"
                    )
                    logger.warning("å°†å°è¯•ç»§ç»­å¤„ç†ï¼Œä½†æ•ˆæœå¯èƒ½ä¸ä½³")

                # ============================================================
                # é˜¶æ®µ3: å¹¿å‘Šå‡†å¤‡ï¼ˆæ™ºèƒ½ç‰ˆï¼‰
                # ============================================================
                logger.info("\n" + "=" * 80)
                logger.info("é˜¶æ®µ3: å¹¿å‘Šå‡†å¤‡")
                logger.info("=" * 80)

                # 3.1 æ™ºèƒ½é€‰æ‹©æ’å…¥ç‚¹ï¼ˆä¸‰çº§ç­–ç•¥ï¼‰
                if not analysis.insertion_points:
                    raise Exception("LLMæœªæ‰¾åˆ°åˆé€‚çš„æ’å…¥ç‚¹")

                logger.info("\n[1/5] æ™ºèƒ½é€‰æ‹©æ’å…¥ç‚¹ï¼ˆäººè„¸ä¼˜å…ˆï¼‰...")

                # ç­–ç•¥1: åœ¨LLMæ¨èçš„ç‚¹ä¸­æ‰¾æœ‰ä¸»è®²äººçš„
                insertion_point, keyframe, insertion_time = self._select_insertion_with_speaker(
                    analysis.insertion_points,
                    video_path,
                    metadata,
                    scene.speaker_profile
                )

                if insertion_point is None and scene.speaker_profile:
                    # ç­–ç•¥2: å¦‚æœLLMæ¨èçš„ç‚¹éƒ½æ²¡äººï¼Œä½¿ç”¨ä¸»è®²äººçš„æœ€ä½³å¸§
                    logger.warning("LLMæ¨èçš„æ’å…¥ç‚¹å‡æ— åˆé€‚äººè„¸ï¼Œä½¿ç”¨ä¸»è®²äººæœ€ä½³ç”»é¢")
                    keyframe = scene.speaker_profile.best_frame
                    insertion_time = scene.speaker_profile.best_frame_time
                    insertion_point = analysis.insertion_points[0]  # è¯­ä¹‰ä¸Šä»ç”¨ç¬¬ä¸€ä¸ªç‚¹

                    logger.success(
                        f"âœ“ ä½¿ç”¨ä¸»è®²äººæœ€ä½³ç”»é¢\n"
                        f"  æ—¶é—´: {insertion_time:.1f}s\n"
                        f"  äººè„¸ç½®ä¿¡åº¦: {scene.speaker_profile.confidence_avg:.3f}"
                    )
                elif insertion_point is None:
                    # ç­–ç•¥3: å®Œå…¨æ‰¾ä¸åˆ°åˆé€‚çš„äººè„¸
                    raise Exception(
                        "æ— æ³•æ‰¾åˆ°åˆé€‚çš„æ’å…¥ç‚¹ï¼š\n"
                        "  - LLMæ¨èçš„ç‚¹å‡æ— äººè„¸\n"
                        "  - è§†é¢‘ä¸­æœªè¯†åˆ«åˆ°ä¸»è®²äºº\n"
                        "å»ºè®®ï¼šè¯·ä½¿ç”¨å•äººå£æ’­ç±»å‹çš„è§†é¢‘"
                    )

                logger.info(f"  æœ€ç»ˆæ’å…¥æ—¶é—´: {insertion_time:.1f}ç§’")
                logger.info(f"  ç†ç”±: {insertion_point.reason}")

                # 3.2 æå–æ’å…¥ç‚¹é™„è¿‘çš„éŸ³é¢‘ç‰‡æ®µç”¨äºå£°éŸ³å…‹éš†ï¼ˆ5-10ç§’ï¼‰
                logger.info("\n[2/5] æå–æ’å…¥ç‚¹é™„è¿‘éŸ³é¢‘ç‰‡æ®µï¼ˆå£°éŸ³å…‹éš†å‚è€ƒï¼‰...")

                # è®¡ç®—éŸ³é¢‘ç‰‡æ®µèŒƒå›´ï¼šæ’å…¥ç‚¹å‰åå„2.5-5ç§’
                audio_clip_duration = 10.0  # æ€»å…±10ç§’
                clip_start = max(0, insertion_time - audio_clip_duration / 2)
                clip_end = min(metadata.duration, insertion_time + audio_clip_duration / 2)

                # å¦‚æœæ¥è¿‘è§†é¢‘å¼€å¤´æˆ–ç»“å°¾,è°ƒæ•´èŒƒå›´ä¿è¯è‡³å°‘5ç§’
                min_clip_duration = 5.0
                if clip_end - clip_start < min_clip_duration:
                    if clip_start == 0:
                        clip_end = min(min_clip_duration, metadata.duration)
                    else:
                        clip_start = max(0, metadata.duration - min_clip_duration)

                logger.info(f"  éŸ³é¢‘ç‰‡æ®µèŒƒå›´: {clip_start:.1f}s ~ {clip_end:.1f}s (æ—¶é•¿: {clip_end - clip_start:.1f}s)")

                # æå–éŸ³é¢‘ç‰‡æ®µ
                reference_audio_clip_path = file_mgr.base_dir / "audio" / "reference_clip.wav"
                with VideoProcessor(str(video_path)) as processor:
                    processor.extract_audio(
                        str(reference_audio_clip_path),
                        start_time=clip_start,
                        end_time=clip_end
                    )

                # å¯¹éŸ³é¢‘ç‰‡æ®µè¿›è¡Œäººå£°åˆ†ç¦»
                logger.info("  åˆ†ç¦»éŸ³é¢‘ç‰‡æ®µä¸­çš„äººå£°...")
                reference_vocals_clip_path = file_mgr.base_dir / "audio" / "reference_vocals_clip.wav"
                self.audio_separator.separate_simple(
                    audio_path=str(reference_audio_clip_path),
                    output_path=str(reference_vocals_clip_path),
                    device=device
                )

                logger.success(f"  âœ“ å£°éŸ³å…‹éš†å‚è€ƒéŸ³é¢‘å·²å‡†å¤‡: {clip_end - clip_start:.1f}ç§’çº¯å‡€äººå£°")

                # 3.3 ä¿å­˜å…³é”®å¸§
                logger.info("\n[3/6] ä¿å­˜å…³é”®å¸§...")
                from PIL import Image
                keyframe_path = file_mgr.get_keyframe_path("insertion_keyframe.jpg")
                Image.fromarray(keyframe).save(str(keyframe_path), quality=95)
                logger.success("  âœ“ å…³é”®å¸§å·²ä¿å­˜ï¼ˆå°†ä½œä¸ºæ•°å­—äººç¬¬ä¸€å¸§ï¼‰")

                # 3.4 ç¡®è®¤äººè„¸è´¨é‡
                logger.info("\n[4/6] ç¡®è®¤äººè„¸è´¨é‡...")
                faces = self.face_detector.detect_faces(keyframe)
                if faces:
                    best_face = max(faces, key=lambda f: f.confidence)
                    logger.success(f"  âœ“ æ£€æµ‹åˆ°{len(faces)}ä¸ªäººè„¸")
                    logger.info(f"  æœ€ä½³äººè„¸ç½®ä¿¡åº¦: {best_face.confidence:.3f}")
                else:
                    logger.warning("  âš ï¸ æœªæ£€æµ‹åˆ°äººè„¸ï¼ˆå·²æ˜¯æœ€ä¼˜é€‰æ‹©ï¼‰")

                # 3.5 é€‰æ‹©å¹¿å‘Š
                logger.info("\n[5/6] é€‰æ‹©å¹¿å‘Š...")
                ad = self.ads_manager.select_ad_for_video(analysis.theme)

                if not ad:
                    raise Exception("æ²¡æœ‰å¯ç”¨çš„å¹¿å‘Š")

                logger.success(f"  âœ“ é€‰ä¸­å¹¿å‘Š: {ad.name}")
                logger.info(f"  äº§å“: {ad.product}")
                logger.info(f"  å–ç‚¹: {ad.get_selling_points_text()}")

                # 3.6 ç”Ÿæˆå¹¿å‘Šè¯
                logger.info("\n[6/6] ç”Ÿæˆå¹¿å‘Šè¯...")
                ad_script = self.llm_service.generate_ad_script(
                    video_theme=analysis.theme,
                    video_category=analysis.category,
                    video_tone=analysis.tone,
                    context_before=insertion_point.context_before,
                    context_after=insertion_point.context_after,
                    ad_config=ad,
                    transition_hint=insertion_point.transition_hint,
                    language=transcription.language  # ä½¿ç”¨æ£€æµ‹åˆ°çš„è¯­è¨€
                )

                logger.success("  âœ“ å¹¿å‘Šè¯ç”Ÿæˆå®Œæˆ")
                logger.info(f"  å†…å®¹: {ad_script}")

                # ============================================================
                # é˜¶æ®µ4: æ•°å­—äººè§†é¢‘ç”Ÿæˆ
                # ============================================================
                logger.info("\n" + "=" * 80)
                logger.info("é˜¶æ®µ4: æ•°å­—äººè§†é¢‘ç”Ÿæˆ")
                logger.info("=" * 80)

                ad_output_dir = file_mgr.base_dir / "ad_video"

                logger.info("\næ‰§è¡Œä¸‰æ­¥workflow: å›¾ç‰‡æ¸…æ´— â†’ å£°éŸ³å…‹éš† â†’ æ•°å­—äººç”Ÿæˆ")

                ad_result = self.ad_orchestrator.generate_ad_video_simple(
                    keyframe_image_path=str(keyframe_path),
                    reference_audio_path=str(reference_vocals_clip_path),  # ä½¿ç”¨æ’å…¥ç‚¹é™„è¿‘çš„éŸ³é¢‘ç‰‡æ®µ
                    ad_script=ad_script,
                    output_dir=str(ad_output_dir),
                    video_width=None,  # ç¦ç”¨å›¾ç‰‡ç¼©æ”¾ä»¥ä¿æŒæœ€é«˜ç”»è´¨
                    video_height=None  # ç¦ç”¨å›¾ç‰‡ç¼©æ”¾ä»¥ä¿æŒæœ€é«˜ç”»è´¨
                )

                if not ad_result.success:
                    raise Exception(f"æ•°å­—äººè§†é¢‘ç”Ÿæˆå¤±è´¥: {ad_result.error_message}")

                logger.success("âœ“ æ•°å­—äººè§†é¢‘ç”Ÿæˆå®Œæˆ")

                # ============================================================
                # é˜¶æ®µ5: è§†é¢‘åˆæˆ
                # ============================================================
                logger.info("\n" + "=" * 80)
                logger.info("é˜¶æ®µ5: è§†é¢‘åˆæˆ")
                logger.info("=" * 80)

                logger.info("\nå°†æ•°å­—äººå¹¿å‘Šæ’å…¥åŸè§†é¢‘...")

                final_output_path = output_dir / f"{video_id}_with_ad.mp4"

                # æ’å…¥å¹¿å‘Šè§†é¢‘
                self.video_composer.insert_ad_video(
                    original_video_path=str(video_path),
                    ad_video_path=ad_result.digital_human_video_path,
                    insertion_time=insertion_point.time,
                    output_path=str(final_output_path)
                )

                logger.success("âœ“ è§†é¢‘åˆæˆå®Œæˆ")

                # ============================================================
                # å®Œæˆ
                # ============================================================
                elapsed_time = time.time() - start_time

                logger.info("\n" + "=" * 80)
                logger.success("ğŸ‰ è§†é¢‘å¤„ç†å®Œæˆï¼")
                logger.info("=" * 80)
                logger.info(f"å¤„ç†æ—¶é—´: {elapsed_time:.1f}ç§’ ({elapsed_time/60:.1f}åˆ†é’Ÿ)")
                logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")

                return ProcessingResult(
                    video_id=video_id,
                    original_video_path=str(video_path),
                    output_video_path=str(final_output_path),
                    success=True,
                    processing_time=elapsed_time,
                    transcription_text=transcription.full_text,
                    video_theme=analysis.theme,
                    insertion_time=insertion_point.time,
                    ad_script=ad_script,
                    digital_human_video=ad_result.digital_human_video_path
                )

        except Exception as e:
            elapsed_time = time.time() - start_time

            logger.error(f"\nâŒ è§†é¢‘å¤„ç†å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())

            return ProcessingResult(
                video_id=video_id,
                original_video_path=str(video_path),
                output_video_path=None,
                success=False,
                error_message=str(e),
                processing_time=elapsed_time
            )

    def batch_process(
        self,
        video_dir: str,
        output_dir: Optional[str] = None,
        device: str = "cuda"
    ) -> list[ProcessingResult]:
        """
        æ‰¹é‡å¤„ç†è§†é¢‘

        Args:
            video_dir: è§†é¢‘ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            device: è®¾å¤‡

        Returns:
            å¤„ç†ç»“æœåˆ—è¡¨
        """
        video_dir = Path(video_dir)
        video_files = list(video_dir.glob("*.mp4"))

        logger.info(f"æ‰¹é‡å¤„ç†: æ‰¾åˆ°{len(video_files)}ä¸ªè§†é¢‘æ–‡ä»¶")

        results = []

        for i, video_file in enumerate(video_files, 1):
            logger.info(f"\n{'=' * 80}")
            logger.info(f"å¤„ç†è¿›åº¦: {i}/{len(video_files)}")
            logger.info(f"{'=' * 80}")

            result = self.process_video(
                video_path=str(video_file),
                output_dir=output_dir,
                device=device
            )

            results.append(result)

        # æ±‡æ€»
        success_count = sum(1 for r in results if r.success)
        total_time = sum(r.processing_time for r in results)

        logger.info("\n" + "=" * 80)
        logger.info("æ‰¹é‡å¤„ç†æ±‡æ€»")
        logger.info("=" * 80)
        logger.info(f"æ€»è®¡: {len(results)}ä¸ªè§†é¢‘")
        logger.info(f"æˆåŠŸ: {success_count}ä¸ª")
        logger.info(f"å¤±è´¥: {len(results) - success_count}ä¸ª")
        logger.info(f"æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
        logger.info(f"å¹³å‡: {total_time/len(results)/60:.1f}åˆ†é’Ÿ/è§†é¢‘")

        return results

    def _select_insertion_with_speaker(
        self,
        candidate_points: list[InsertionPoint],
        video_path: Path,
        metadata,
        speaker_profile: Optional[SpeakerProfile]
    ) -> tuple[Optional[InsertionPoint], Optional[np.ndarray], float]:
        """
        åœ¨å€™é€‰ç‚¹ä¸­é€‰æ‹©æœ‰ä¸»è®²äººçš„æ’å…¥ç‚¹

        Returns:
            (æ’å…¥ç‚¹, å…³é”®å¸§, æ—¶é—´) æˆ– (None, None, 0.0) å¦‚æœéƒ½ä¸åˆé€‚
        """
        logger.info(f"è¯„ä¼° {len(candidate_points)} ä¸ªå€™é€‰æ’å…¥ç‚¹...")

        scored_points = []

        cap = cv2.VideoCapture(str(video_path))
        fps = cap.get(cv2.CAP_PROP_FPS)

        for point in candidate_points:
            # æå–æ’å…¥ç‚¹çš„å‰ä¸€å¸§ï¼ˆè¿™å°†ä½œä¸ºæ•°å­—äººè§†é¢‘çš„ç¬¬ä¸€å¸§ï¼‰
            frame_number = int(point.time * fps) - 1
            cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, frame_number))
            ret, frame = cap.read()

            if not ret:
                logger.debug(f"  å€™é€‰ç‚¹ {point.time:.1f}s: æ— æ³•è¯»å–å¸§")
                continue

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # æ£€æµ‹äººè„¸
            faces = self.face_detector.detect_faces(frame_rgb)

            if not faces:
                logger.info(f"  å€™é€‰ç‚¹ {point.time:.1f}s: âŒ æ— äººè„¸")
                continue

            # å¦‚æœæœ‰ä¸»è®²äººæ¡£æ¡ˆï¼Œæ£€æŸ¥æ˜¯å¦åŒ¹é…
            if speaker_profile:
                is_main_speaker, best_face = self.speaker_detector.is_main_speaker_in_frame(
                    frame_rgb,
                    speaker_profile
                )

                if not is_main_speaker:
                    logger.info(
                        f"  å€™é€‰ç‚¹ {point.time:.1f}s: âš ï¸ æœ‰äººè„¸ä½†ä¸æ˜¯ä¸»è®²äºº"
                    )
                    continue

                # ç»¼åˆè¯„åˆ†ï¼šè¯­ä¹‰ä¼˜å…ˆçº§ + äººè„¸è´¨é‡
                semantic_score = (4 - point.priority) / 3  # priority 1->1.0, 2->0.66, 3->0.33
                face_score = best_face.confidence
                combined_score = semantic_score * 0.4 + face_score * 0.6

                scored_points.append({
                    'point': point,
                    'frame': frame_rgb,
                    'score': combined_score,
                    'face_confidence': face_score
                })

                logger.success(
                    f"  å€™é€‰ç‚¹ {point.time:.1f}s: âœ“ ä¸»è®²äººç”»é¢ "
                    f"(ç½®ä¿¡åº¦={face_score:.3f}, ç»¼åˆåˆ†={combined_score:.3f})"
                )
            else:
                # æ²¡æœ‰ä¸»è®²äººæ¡£æ¡ˆï¼Œåªè¦æœ‰äººè„¸å°±è¡Œ
                best_face = max(faces, key=lambda f: f.confidence)
                semantic_score = (4 - point.priority) / 3
                combined_score = semantic_score * 0.5 + best_face.confidence * 0.5

                scored_points.append({
                    'point': point,
                    'frame': frame_rgb,
                    'score': combined_score,
                    'face_confidence': best_face.confidence
                })

                logger.info(
                    f"  å€™é€‰ç‚¹ {point.time:.1f}s: âœ“ æœ‰äººè„¸ "
                    f"(ç½®ä¿¡åº¦={best_face.confidence:.3f})"
                )

        cap.release()

        if not scored_points:
            logger.warning("âš ï¸ æ‰€æœ‰å€™é€‰ç‚¹å‡æ— åˆé€‚äººè„¸")
            return None, None, 0.0

        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„
        best = max(scored_points, key=lambda x: x['score'])

        logger.success(
            f"âœ“ é€‰ä¸­æ’å…¥ç‚¹: {best['point'].time:.1f}s "
            f"(äººè„¸ç½®ä¿¡åº¦={best['face_confidence']:.3f})"
        )

        return best['point'], best['frame'], best['point'].time

